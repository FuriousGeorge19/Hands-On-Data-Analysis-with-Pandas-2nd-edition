{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises: Chapter 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. With the `earthquakes.csv` file, select all the earthquakes in Japan with a magnitude of 4.9 or greater using the mb magnitude type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls exercises/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -5 exercises/earthquakes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes = pd.read_csv('exercises/earthquakes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes.loc[lambda x: (x.mag >= 4.9) & (x.magType == 'mb') & (x.parsed_place == 'Japan') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes[quakes.mag.ge(4.9) & (quakes.magType.eq('mb')) & (quakes.parsed_place.eq('Japan'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes[quakes.mag.ge(4.9) & quakes.magType.eq('mb')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes.query('(mag >= 4.9) and (magType == \"mb\") and (parsed_place == \"Japan\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create bins for each full number of earthquake magnitude (for instance, the first bin is (0, 1], the second is (1, 2], and so on) with the ml magnitude type and count how many are in each bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##??pd.cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_mags = (\n",
    "    quakes\n",
    "    .query('magType == \"ml\"')['mag']\n",
    "    .to_frame()\n",
    ")\n",
    "\n",
    "# find min and max values\n",
    "# agg might not work on a series\n",
    "ml_mags.agg({'mag':['min', 'max']}).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_mag_bins = pd.cut(ml_mags.squeeze(), bins = range(-2,7))\n",
    "ml_mag_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_mag_bins.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_mag_bins.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Using the faang.csv file, group by the ticker and resample to monthly frequency. Make the following aggregations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Mean of opening price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Maximum of the high price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Minimum of the low price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Mean of the closing price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Sum of the volume traded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -5 exercises/faang.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang = pd.read_csv('exercises/faang.csv')\n",
    "faang.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.info() # to group by month, want to make date the index as a datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang = pd.read_csv('exercises/faang.csv', index_col='date', parse_dates=True)\n",
    "faang.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( faang\n",
    " .groupby('ticker')\n",
    " .resample('M')\n",
    " .agg({\n",
    "     'open':'mean',\n",
    "     'high':'max',\n",
    "     'low':'min',\n",
    "     'close':'mean',\n",
    "     'volume':'sum'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Build a crosstab with the earthquake data between the tsunami column and the magType column. Rather than showing the frequency count, show the maximum magnitude that was observed for each combination. Put the magnitude type along the columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=quakes.magType, columns=quakes.tsunami, values=quakes.mag, aggfunc=max )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=quakes.tsunami, columns= quakes.magType, values=quakes.mag, aggfunc=max )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quakes.query('magType==\"mwb\" and tsunami==0')['mag'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Calculate the rolling 60-day aggregations of the OHLC data by ticker for the FAANG data. Use the same aggregations as exercise 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( faang\n",
    " .groupby('ticker')\n",
    " .rolling('60D')\n",
    " .agg({\n",
    "     'open':'mean',\n",
    "     'high':'max',\n",
    "     'low':'min',\n",
    "     'close':'mean',\n",
    "     'volume':'sum'})\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\"><span style=\"color:green\">    ***INTERESTING, CONSEQUENTIAL ERROR ON MY PART. I ORIGINALLY SPECIFIED `rolling(60)`, WHICH WILL DO THE LAST 60 OBSERVATIONS. WHICH IS A SPAN OF MORE THAN 60 DAYS WITH TRADING DATA. I SHOULD HAVE SPECIFIED `rolling('60D')`.*** </span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### 6. Create a pivot table of the FAANG data that compares the stocks. Put the ticker in the rows and show the averages of the OHLC and volume traded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(faang, index='ticker', aggfunc='mean', values=['open', 'high', 'low', 'close', 'volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Calculate the Z-scores for each numeric column of Amazon's data (ticker is AMZN) in Q4 2018 using `apply()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    faang\n",
    "    .query('ticker==\"AMZN\"')\n",
    "    .loc['2018-Q4']\n",
    "    .drop(columns='ticker')\n",
    "    .apply(\n",
    "        lambda x: x.sub(x.mean()).div(x.std())\n",
    "    )\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Add event descriptions:   \n",
    "a) Create a dataframe with the following three columns: ticker, date, and event. The columns should have the following values:    \n",
    "> i) ticker: 'FB'    \n",
    "ii) date: ['2018-07-25', '2018-03-19', '2018-03-20']    \n",
    "iii) event: ['Disappointing user growth announced after close.', 'Cambridge Analytica story', 'FTC investigation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df = pd.DataFrame({\n",
    "    'ticker': 'FB',\n",
    "    'date':  ['2018-07-25', '2018-03-19', '2018-03-20'],\n",
    "    'event': ['Disappointing user growth announced after close.', 'Cambridge Analytica story', 'FTC investigation']\n",
    "    })\n",
    "\n",
    "event_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df.info() # first time through, I hadn't realized `date` wasn't a datetime in this dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make date datetime\n",
    "event_df['date'] = pd.to_datetime(event_df['date'])\n",
    "event_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put date and ticker into the index\n",
    "event_df = event_df.set_index(['date', 'ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- event_df has a multi index\n",
    "- faang has date only in the index\n",
    "- Here's how to move `ticker` into faang's index w/out replacing `date', but rather augmenting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.info() # faang's index IS datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date was already in the index, reset_index kicks the existing index into the values\n",
    "# to ADD ticker to the index, need to specify append=True\n",
    "\n",
    "faang.set_index('ticker', append=True).sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_w_events= (\n",
    "    faang\n",
    "    .set_index('ticker', append=True) # add ticker to date in the index\n",
    "    .merge(\n",
    "        event_df, #needs to have date and ticker in the index...see above\n",
    "        how='outer',\n",
    "        left_index=True, # to merge on an index as opposed to a dataframe column\n",
    "        right_index=True # ditto\n",
    "    )\n",
    ")\n",
    "\n",
    "faang_w_events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_w_events.loc[[x[0]  for x in event_df.index], :] #just picks out the dates to confirm they're in the merged dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\"> 9. Use the `transform()` method on the FAANG data to represent all the values in terms of the first date in the data. To do so, divide all the values for each ticker by the values for the first date in the data for that ticker. This is referred to as an index, and the data for the first date is the base (https://ec.europa.eu/eurostat/statistics-explained/index.php/Beginners:Statistical_concept_-_Index_and_base_year). When data is in this format, we can easily see growth over time. Hint: transform() can take a function name.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <div class=\"alert alert-info\"><span style=\"color:green\">    ***Very, very useful exercise. Worth reviewing in the future and documenting in Notion.*** </span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.groupby('ticker').head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" >To get the denominator for this calculation, we need to:</span>\n",
    "##### <span style=\"color:green\" >- Group by ticker</span>      \n",
    "##### <span style=\"color:green\" >- Find the first valid value for each ticker for each series</span>\n",
    "\n",
    "##### <span style=\"color:green\" >The first part isn't terribly difficult. Group by `ticker` and then get the `first` value for each series and use `transform()` to have it applied to each date for each ticker </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    faang\n",
    "    .groupby('ticker')\n",
    "    .transform('first')\n",
    "    .loc[lambda x: x.index <= '2018-01-04']\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    faang\n",
    "    .set_index('ticker', append=True)\n",
    "    .groupby('ticker')\n",
    "    .transform('first')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (\n",
    "#     faang\n",
    "#     .reset_index().set_index(['ticker', 'date'])\n",
    "#     .groupby('ticker')\n",
    "#     .transform('first')\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" > When I saw this I had two thoughts:  </span>\n",
    "##### <span style=\"color:green\" >- This problem might not be that hard...divide all the values in `faang` by the values above...and we're done!</span>      \n",
    "##### <span style=\"color:green\" >- But....the `groupby` I did above has lost the tickers. Even if the calculations were correct, losing the ticker information makes the data close to useless in a practical sense and it also makes the accuracy difficult to confirm. </span>\n",
    "\n",
    "##### <span style=\"color:green\" > Still...I went ahead and performed the calculation to make sure the general method would work. I had to drop the `ticker` column to make the columns lined up, but this *looks* like the calculation you'd want.   </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.drop(columns='ticker').div(faang.groupby('ticker').transform('first'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" > To make this work, before doing any of the grouping and transforming...I needed to move the ticker into index along w/the date...</span>     \n",
    "##### <span style=\"color:green\" > ...`set_index` to `ticker` would drop `date` and replace it with `ticker`. So I had to find the `append=True` option for `set_index` to put both `date` and `ticker` in the index.</span>     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang.set_index('ticker', append=True).sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\" > Repeating what I did above, but with `date` and `ticker` in the index was straightforward.</span>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    faang\n",
    "    .set_index('ticker', append=True)\n",
    "    .apply(\n",
    "        lambda x: x.groupby(['ticker']).transform('first')\n",
    "    )\n",
    ")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" > Finally, I put it all together:</span>    \n",
    "##### <span style=\"color:green\" > - The numerator is just `faang` with both `date` and `ticker` in index.</span>    \n",
    "##### <span style=\"color:green\" > - The denominators are the first values for each ticker/series that we created above, again with both `date` and `ticker` in the index.</span>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_indexed = \\\n",
    "(faang\n",
    " .set_index('ticker', append=True) # put both `date` and `ticker` into faang's index\n",
    " .div(faang                                  # divide by the first value of each ticker, using what we did in the cell above\n",
    "      .set_index('ticker', append=True)\n",
    "      .apply(lambda x: x.groupby(['ticker']).transform('first'))\n",
    "     )\n",
    ")\n",
    "\n",
    "faang_indexed.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" > (After reviewing things, a much more intuitive solution is below:)</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(faang\n",
    " .set_index('ticker', append=True) # creates the same multi-index w/date and ticker in the index as the denominator\n",
    " .div(\n",
    "     faang\n",
    "    .set_index('ticker', append=True)\n",
    "    .groupby('ticker')\n",
    "    .transform('first')\n",
    " )\n",
    ").query('date <= \"2018-01-04\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\" > So I did it! </span>  \n",
    "#### <span style=\"color:green\" > But I also needed to confirm it worked.  </span>    \n",
    "#### <span style=\"color:green\" > One thing that needed to be true if this solution was correct was that the first date for each ticker for each series would be equal to 1.0000. </span> \n",
    "#### <span style=\"color:green\" > Doing this with regular indexing wasn't very easy. What I started with is further down.  </span>  \n",
    "#### <span style=\"color:green\" > However, doing this with `query` turns out to be blessedly easy and straightforward. See the code and output below. </span>  \n",
    "#### <span style=\"color:green\" > ALSO NOTE THAT `first` PROBABLY DEPENDS ON THE DATA BEING SORTED BY `date`.  </span>  \n",
    "\n",
    "#### <span style=\"color:green\" > `query()` makes it very easy to select rows, in the index or from the columns.  </span>  \n",
    "#### <span style=\"color:green\" > (Apparently, selecting columns with `query()` is strongly discouraged.)  </span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\" > **Pick out single values of `date` and `ticker`.** </span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_indexed.loc[\"12-17-18\", \"AMZN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:green\" > This works as well. The whole query clause has to be placed in quotes and each conditional needs to be placed in parentheses () in order to avoid confusion on the part of python regarding operator precedence.  </span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_indexed.query('(date == \"12-17-18\") & (ticker == \"AMZN\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\" > **Pick out multiple values of `date` and `ticker`.** </span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" > Key details: </span>  \n",
    "##### <span style=\"color:green\" > - The index choices must be enclosed in parentheses </span>  \n",
    "##### <span style=\"color:green\" > - The indexing for both the index and the columns MUST be included </span>  \n",
    "##### <span style=\"color:green\" > - In this example, that's why `((\"12-17-18\", \"12-21-18\"), (\"AMZN\", \"GOOG\"))` is followed by `, :`. The latter is the specification of \"all columns\" </span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_indexed.loc[((\"12-17-18\", \"12-21-18\"), (\"AMZN\", \"GOOG\")), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" > A *nearly* equivalent formulation with `query()`.</span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_indexed.query('(date in  [\"12-17-18\", \"12-21-18\"]) & (ticker in [\"AMZN\", \"GOOG\"])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" > Adding `sort_index` addresses the difference.</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_indexed.query('(date in  [\"12-17-18\", \"12-21-18\"]) & (ticker in [\"AMZN\", \"GOOG\"])').sort_index(level=0, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\" > **Pick out multiple `date` values but ALL `ticker`s.** </span>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_indexed.loc[((\"12-17-18\", \"12-19-18\"), slice(None)), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" > `IndexSlice` allows you to stop using `Slice` and parentheses and return to using the more natural `:` and `[]`s .</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "faang_indexed.loc[ idx[[\"12-17-18\", \"12-19-18\"], :], idx[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faang_indexed.loc[ idx[[\"12-17-18\", \"12-19-18\"], :], idx['high':'open']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" > The `query` version of this is probably the easiest of them all, but would require sorting the index to produce the same ordering at the other two solutions: </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "faang_indexed.query('date in(\"12-17-18\", \"12-19-18\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:green\" > **Pick out a `date` range.** </span>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" > Interestingly...this will NOT work: </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-01-02</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-03-29</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.996808</td>\n",
       "      <td>0.986057</td>\n",
       "      <td>0.986189</td>\n",
       "      <td>0.973993</td>\n",
       "      <td>1.502530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1.223084</td>\n",
       "      <td>1.166329</td>\n",
       "      <td>1.199659</td>\n",
       "      <td>1.217265</td>\n",
       "      <td>4.669178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>0.888975</td>\n",
       "      <td>0.868150</td>\n",
       "      <td>0.873199</td>\n",
       "      <td>0.880774</td>\n",
       "      <td>3.274274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>0.977562</td>\n",
       "      <td>0.959502</td>\n",
       "      <td>0.964983</td>\n",
       "      <td>0.968817</td>\n",
       "      <td>2.203297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>1.464667</td>\n",
       "      <td>1.411831</td>\n",
       "      <td>1.463539</td>\n",
       "      <td>1.468891</td>\n",
       "      <td>1.745753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       high       low      open     close    volume\n",
       "date       ticker                                                  \n",
       "2018-01-02 AAPL    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           AMZN    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           FB      1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           GOOG    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           NFLX    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "...                     ...       ...       ...       ...       ...\n",
       "2018-03-29 AAPL    0.996808  0.986057  0.986189  0.973993  1.502530\n",
       "           AMZN    1.223084  1.166329  1.199659  1.217265  4.669178\n",
       "           FB      0.888975  0.868150  0.873199  0.880774  3.274274\n",
       "           GOOG    0.977562  0.959502  0.964983  0.968817  2.203297\n",
       "           NFLX    1.464667  1.411831  1.463539  1.468891  1.745753\n",
       "\n",
       "[305 rows x 5 columns]"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faang_indexed.loc[(slice(\"2018-01\",\"2018-03\"), slice(None)), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" > `slice`ing on dates requires the index to be sorted </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-01-02</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-03-29</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.996808</td>\n",
       "      <td>0.986057</td>\n",
       "      <td>0.986189</td>\n",
       "      <td>0.973993</td>\n",
       "      <td>1.502530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1.223084</td>\n",
       "      <td>1.166329</td>\n",
       "      <td>1.199659</td>\n",
       "      <td>1.217265</td>\n",
       "      <td>4.669178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>0.888975</td>\n",
       "      <td>0.868150</td>\n",
       "      <td>0.873199</td>\n",
       "      <td>0.880774</td>\n",
       "      <td>3.274274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>0.977562</td>\n",
       "      <td>0.959502</td>\n",
       "      <td>0.964983</td>\n",
       "      <td>0.968817</td>\n",
       "      <td>2.203297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>1.464667</td>\n",
       "      <td>1.411831</td>\n",
       "      <td>1.463539</td>\n",
       "      <td>1.468891</td>\n",
       "      <td>1.745753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       high       low      open     close    volume\n",
       "date       ticker                                                  \n",
       "2018-01-02 AAPL    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           AMZN    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           FB      1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           GOOG    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           NFLX    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "...                     ...       ...       ...       ...       ...\n",
       "2018-03-29 AAPL    0.996808  0.986057  0.986189  0.973993  1.502530\n",
       "           AMZN    1.223084  1.166329  1.199659  1.217265  4.669178\n",
       "           FB      0.888975  0.868150  0.873199  0.880774  3.274274\n",
       "           GOOG    0.977562  0.959502  0.964983  0.968817  2.203297\n",
       "           NFLX    1.464667  1.411831  1.463539  1.468891  1.745753\n",
       "\n",
       "[305 rows x 5 columns]"
      ]
     },
     "execution_count": 794,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faang_indexed.sort_values(by=['date', 'ticker'], inplace=True)\n",
    "faang_indexed.loc[(slice(\"2018-01\",\"2018-03\"), slice(None)), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" > IndexSlicer again lets us use clearer syntax, or at least similar to other Pandas and Python syntax </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-01-02</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-03-29</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.996808</td>\n",
       "      <td>0.986057</td>\n",
       "      <td>0.986189</td>\n",
       "      <td>0.973993</td>\n",
       "      <td>1.502530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1.223084</td>\n",
       "      <td>1.166329</td>\n",
       "      <td>1.199659</td>\n",
       "      <td>1.217265</td>\n",
       "      <td>4.669178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>0.888975</td>\n",
       "      <td>0.868150</td>\n",
       "      <td>0.873199</td>\n",
       "      <td>0.880774</td>\n",
       "      <td>3.274274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>0.977562</td>\n",
       "      <td>0.959502</td>\n",
       "      <td>0.964983</td>\n",
       "      <td>0.968817</td>\n",
       "      <td>2.203297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>1.464667</td>\n",
       "      <td>1.411831</td>\n",
       "      <td>1.463539</td>\n",
       "      <td>1.468891</td>\n",
       "      <td>1.745753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       high       low      open     close    volume\n",
       "date       ticker                                                  \n",
       "2018-01-02 AAPL    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           AMZN    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           FB      1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           GOOG    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           NFLX    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "...                     ...       ...       ...       ...       ...\n",
       "2018-03-29 AAPL    0.996808  0.986057  0.986189  0.973993  1.502530\n",
       "           AMZN    1.223084  1.166329  1.199659  1.217265  4.669178\n",
       "           FB      0.888975  0.868150  0.873199  0.880774  3.274274\n",
       "           GOOG    0.977562  0.959502  0.964983  0.968817  2.203297\n",
       "           NFLX    1.464667  1.411831  1.463539  1.468891  1.745753\n",
       "\n",
       "[305 rows x 5 columns]"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faang_indexed.loc[idx[\"2018-01\" : \"2018-03\", :],  idx[:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <span style=\"color:green\" > This might be a case where `query()` isn't as handy as it was in other applications. There may be a way to get it to handle date shorthand like \"2018-Q1\" or  \"2018-01\":\"2018-03\", but I couldn't find a good reference for how to do it. </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-01-02</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2018-03-29</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.996808</td>\n",
       "      <td>0.986057</td>\n",
       "      <td>0.986189</td>\n",
       "      <td>0.973993</td>\n",
       "      <td>1.502530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AMZN</th>\n",
       "      <td>1.223084</td>\n",
       "      <td>1.166329</td>\n",
       "      <td>1.199659</td>\n",
       "      <td>1.217265</td>\n",
       "      <td>4.669178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FB</th>\n",
       "      <td>0.888975</td>\n",
       "      <td>0.868150</td>\n",
       "      <td>0.873199</td>\n",
       "      <td>0.880774</td>\n",
       "      <td>3.274274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOG</th>\n",
       "      <td>0.977562</td>\n",
       "      <td>0.959502</td>\n",
       "      <td>0.964983</td>\n",
       "      <td>0.968817</td>\n",
       "      <td>2.203297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NFLX</th>\n",
       "      <td>1.464667</td>\n",
       "      <td>1.411831</td>\n",
       "      <td>1.463539</td>\n",
       "      <td>1.468891</td>\n",
       "      <td>1.745753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>305 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       high       low      open     close    volume\n",
       "date       ticker                                                  \n",
       "2018-01-02 AAPL    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           AMZN    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           FB      1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           GOOG    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "           NFLX    1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "...                     ...       ...       ...       ...       ...\n",
       "2018-03-29 AAPL    0.996808  0.986057  0.986189  0.973993  1.502530\n",
       "           AMZN    1.223084  1.166329  1.199659  1.217265  4.669178\n",
       "           FB      0.888975  0.868150  0.873199  0.880774  3.274274\n",
       "           GOOG    0.977562  0.959502  0.964983  0.968817  2.203297\n",
       "           NFLX    1.464667  1.411831  1.463539  1.468891  1.745753\n",
       "\n",
       "[305 rows x 5 columns]"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = '2018-01-01'\n",
    "end_date = '2018-03-31'\n",
    "faang_indexed.query('(date >= @start_date) & (date <= @end_date)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. The European Centre for Disease Prevention and Control (ECDC) provides an open dataset on COVID-19 cases called daily number of new reported cases of COVID-19 by country worldwide (https://www.ecdc.europa.eu/en/publications-data/download-todays-data-geographic-distribution-covid-19-cases-worldwide). This dataset is updated daily, but we will use a snapshot that contains data through September 18, 2020. Complete the following tasks to practice the skills you've learned up to this point in the book: \n",
    "\n",
    "a) Prepare the data:   \n",
    "i) Read in the data in the covid19_cases.csv file.   \n",
    "ii) Create a date column by parsing the dateRep column into a datetime.    \n",
    "iii) Set the date column as the index.     \n",
    "iv) Use the replace() method to update all occurrences of United_States_of_America and United_Kingdom to USA and UK, respectively.      \n",
    "v) Sort the index.     \n",
    "b) For the five countries with the most cases (cumulative), find the day with the largest number of cases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -5 ~/Downloads/data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid = pd.read_csv('~/Downloads/data.csv', index_col='dateRep', parse_dates=True, dayfirst=True)\n",
    "covid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#?pd.read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#??pd.DataFrame.replace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The instructions say the data is through 9/18/2020, so we'll cap the new data at that date so my results can match hers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid = covid.query('dateRep <= \"2020-09-18\"')\n",
    "covid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid.query('countriesAndTerritories in [\"United_States_of_America\", \"United_Kingdom\"]').sample(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_u = covid.replace({'United_States_of_America':'USA', 'United_Kingdom':'UK'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_u.query('countriesAndTerritories in [\"United_States_of_America\", \"United_Kingdom\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_u.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_u.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_u.index.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_5=\\\n",
    "(covid\n",
    " .assign(\n",
    "     \n",
    "     tot_cases = lambda x: x.groupby('countriesAndTerritories').cases.transform('sum'),\n",
    "     case_rank = lambda x: x.tot_cases.rank(method='dense', ascending=False)\n",
    "     \n",
    " ).query('case_rank <= 5')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_5.groupby('countriesAndTerritories').cases.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_5.groupby('countriesAndTerritories').cases.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_5.groupby('countriesAndTerritories').cases.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid.groupby('countriesAndTerritories').cases.sum().nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
